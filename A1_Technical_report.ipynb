{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1 SEA 600 Technical Report\n",
    "- Fahad Ali Khan\n",
    "- Abhi NileshKumar Patel\n",
    "- Inderpreet Singh Parmar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem & Data Description\n",
    "- Objective: The project aims to predict whether a loan will be approved using historical lending data from LendingClub, a peer-to-peer lending company. This is a binary classification problem where the outcome is whether a loan is approved or not. See: \n",
    "https://figshare.com/articles/dataset/Lending_Club/22121477?file=39316160 \n",
    "\n",
    "- ML Problem Translation: The objective translates into a supervised machine learning problem where the goal is to classify loan applications as approved or not approved based on features extracted from historical data.\n",
    "\n",
    "#### Implementation Constraints:\n",
    "\n",
    "##### Resource Utilization: Models need to be resource-efficient due to constraints on computation time and memory. This affects the choice of algorithms, favoring those with lower complexity.\n",
    "##### Societal Impact: The model's predictions could impact individuals' financial opportunities, necessitating high accuracy and fairness in predictions to avoid discriminatory outcomes.\n",
    "##### Regulatory Compliance: Adherence to financial regulations such as the Equal Credit Opportunity Act (ECOA) is necessary to ensure non-discriminatory lending practices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description and Data preprocessing\n",
    "\n",
    "- Our Target Variable is *Loan_Status* that is used to predict if a persons loan request is accepted or rejected.\n",
    "\n",
    "| Feature Name                | Description |\n",
    "|-----------------------------|-------------|\n",
    "| issue_d                     | The month and year when the loan was funded, indicating when the loan agreement started. |\n",
    "| sub_grade                   | A granular categorization within a broader credit grade, providing a more detailed assessment of credit risk. |\n",
    "| term                        | The duration of the loan term, typically in months, affecting monthly payments and total interest. |\n",
    "| home_ownership              | Indicates the borrower's housing situation (owning, renting, etc.), which can impact creditworthiness. |\n",
    "| fico_range_low              | The lower end of the borrower's FICO score range at application, used to evaluate credit risk. |\n",
    "| total_acc                   | Total number of credit lines in the borrower's credit history, reflecting credit experience and utilization. |\n",
    "| pub_rec                     | Number of derogatory public records on the borrower's credit report, affecting creditworthiness. |\n",
    "| revol_util                  | Percentage of revolving credit used by the borrower, indicating credit utilization and potential risk. |\n",
    "| annual_inc                  | The borrower's self-reported annual income, crucial for assessing loan repayment ability. |\n",
    "| int_rate                    | The interest rate on the loan, directly affecting the cost of borrowing and monthly payments. |\n",
    "| purpose                     | The self-reported reason for the loan, providing context on its intended use. |\n",
    "| mort_acc                    | Number of mortgage accounts, which can signify financial stability and credit history. |\n",
    "| loan_amnt                   | The applied loan amount, influencing the borrower's debt obligations and repayment terms. |\n",
    "| application_type            | Indicates if the application is individual or joint, affecting credit assessment and repayment responsibility. |\n",
    "| installment                 | Monthly payment owed if the loan originates, based on amount, term, and rate. |\n",
    "| verification_status         | Status of income and employment verification, impacting perceived loan risk. |\n",
    "| pub_rec_bankruptcies        | Number of bankruptcy public records, significantly affecting creditworthiness. |\n",
    "| addr_state                  | The borrower's state of residence, useful for geographic risk analysis and regulatory compliance. |\n",
    "| initial_list_status         | Indicates the loan's market status, affecting liquidity and pricing. |\n",
    "| fico_range_high             | The higher end of the borrower's FICO score range, providing a fuller picture of credit standing. |\n",
    "| revol_bal                   | Total balance on revolving accounts, indicating credit utilization and financial management. |\n",
    "| id                          | Unique identifier for the loan or borrower, essential for data tracking. |\n",
    "| open_acc                    | Number of open credit lines, showing credit usage and availability. |\n",
    "| emp_length                  | Employment duration at current job, indicating job stability and income reliability. |\n",
    "| loan_status                 | Current status of the loan, crucial for loan performance assessment. |\n",
    "| time_to_earliest_cr_line    | Time since the first credit line was opened, reflecting credit history length. |\n",
    "\n",
    "#### The Dataset is divided into two with the Test set 90k records and Traning set with 235K records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\fahad\\appdata\\roaming\\python\\python311\\site-packages (from memory_profiler) (5.9.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fahad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"eea19673-8a1f-47e5-b457-2cf9542220c7\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"97f5af23-d19a-4434-9156-b58b765ef3c3\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"9d8fa1a02fec40c3ae4b01dd2213418f\",\"client_comm_id\":\"45e15ab6ca564bd7a4711ef29c204c2d\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"97f5af23-d19a-4434-9156-b58b765ef3c3\",\"roots\":{\"p1002\":\"eea19673-8a1f-47e5-b457-2cf9542220c7\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install -q hvplot\n",
    "# Install memory_profiler \n",
    "%pip install memory_profiler\n",
    "%pip install imbalanced-learn\n",
    "\n",
    "# Load memory_profiler extension\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,  roc_curve, auc, precision_recall_curve, average_precision_score,RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.discriminant_analysis import  LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "\n",
    "pd.set_option('display.float', '{:.2f}'.format)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully\n",
      "Test data imported successfully\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_lending_club.csv\")\n",
    "print(\"Data imported successfully\")\n",
    "test_data = pd.read_csv(\"test_lending_club.csv\")\n",
    "print(\"Test data imported successfully\")\n",
    "\n",
    "#filling Test Data empty values  Training data has no empty records\n",
    "\n",
    "numerical_cols = test_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = test_data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Impute numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "test_data[numerical_cols] = num_imputer.fit_transform(test_data[numerical_cols])\n",
    "\n",
    "# Impute categorical columns with the most frequent value (mode)\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "test_data[categorical_cols] = cat_imputer.fit_transform(test_data[categorical_cols])\n",
    "\n",
    "#One-Hot Encoding\n",
    "# List of categorical columns to convert\n",
    "categorical_columns = ['sub_grade', 'term', 'home_ownership', 'purpose', 'application_type', 'verification_status', 'initial_list_status']\n",
    "\n",
    "# One-hot encode these columns\n",
    "data = pd.get_dummies(data, columns=categorical_columns,drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure that both dataframes have the same dummy columns\n",
    "data, test_data = data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "\n",
    "# Store 'loan_status' in a separate variable and then drop non-feature columns from the training data\n",
    "y_train = data['loan_status']\n",
    "X_train = data.drop(['issue_d', 'loan_status', 'id', 'addr_state'], axis=1)\n",
    "\n",
    "y_test = test_data['loan_status']\n",
    "X_test = test_data.drop(['issue_d', 'loan_status', 'id', 'addr_state'], axis=1)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)  \n",
    "# Fit SMOTE on Training Data\n",
    "X_train, y_train= smote.fit_resample(X_train, y_train)\n",
    "# Fit SMOTE on Testing Data\n",
    "X_test, y_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "# Assuming `X_test` and `y_test` are your existing test features and labels\n",
    "# Split the test set into a smaller test set and a validation set\n",
    "X_test_smaller, X_validation, y_test_smaller, y_validation = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now have Clean processed data\n",
    "\n",
    "- Did you need to clean the data? Why and how? What were your options? Why did you choose your method(s)?\n",
    "- (ANS) Yes we cleaned the data by \n",
    "    - Removing imbalance as the majority class was too high making the models not being able to capture the complexity of the data. We also removed issue_id feature since it conflicted with our ML Problem\n",
    "    the model shouldn't know the date of the loan being rejected/accepted. Id and addr_state features were also removed as they were deemed invalid. \n",
    "\n",
    "- How did you split the data? What were your options? Why did you choose your method(s)?\n",
    "- (ANS) The test data were splitted into half to give validation set. This was done to follow assignment instruction and use test data to only check final accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone I and II\n",
    "- Selected Models : Logistic Regression, KNN, Linear Discriminant Analysis and Decision Trees\n",
    "- Metrics use to evaluate ROC_AUC, PR_AUC, F1_Score, classification report.\n",
    "- *Alternatives Considered* SVM: Since it is good with high dimensional data. However not used because of the large training dataset.\n",
    "- See Code for CV of these models. \n",
    "- See apendix for ROC and PR curves of the CV of the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is the table summarizing the performance and resource utilization of the models on the **training dataset**:\n",
    "\n",
    "| Model                | Precision-Recall AUC | ROC AUC | F1 Score | Training Time (seconds) | Peak Memory (MiB) | Memory Increment (MiB) |\n",
    "|----------------------|----------------------|---------|----------|-------------------------|-------------------|------------------------|\n",
    "| LDA                  | 0.94                 | 0.776   | 0.901    | 2.781                   | 1236.81           | 732.88                 |\n",
    "| Decision Tree        | 0.91                 | 0.552   | 0.810    | 16.527                  | 583.27            | 76.55                  |\n",
    "| Logistic Regression  | 0.94                 | 0.779   | 0.903    | 1.023                   | 824.35            | 147.03                 |\n",
    "| KNN                  | 0.93                 | 0.694   | 0.895    | 0.094                   | 820.09            | 142.79                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Precision-Recall AUC**:\n",
    "   - **LDA** and **Logistic Regression** have the highest Precision-Recall AUC scores at **0.94**, indicating they perform well in terms of both precision (how many selected items are relevant) and recall (how many relevant items are selected).\n",
    "   - **KNN** follows closely with a Precision-Recall AUC of **0.93**.\n",
    "   - **Decision Tree** has the lowest score at **0.91**, which is still quite respectable but indicates it might not perform as well as the other models in distinguishing between the classes, especially in imbalanced datasets.\n",
    "\n",
    "2. **ROC AUC**:\n",
    "   - **Logistic Regression** leads slightly with a ROC AUC of **0.779**, indicating its ability to distinguish between the classes is slightly better than the others.\n",
    "   - **LDA** is a close second with **0.776**.\n",
    "   - **KNN** and **Decision Tree** have lower ROC AUC scores of **0.694** and **0.552** respectively, indicating they may not distinguish as effectively between the classes as the logistic regression and LDA models.\n",
    "\n",
    "3. **F1 Score**:\n",
    "   - Both **LDA** and **Logistic Regression** show high F1 scores of **0.901** and **0.903**, suggesting a strong balance between precision and recall.\n",
    "   - **KNN** has a slightly lower F1 score of **0.895**.\n",
    "   - **Decision Tree** has the lowest F1 score at **0.810**, indicating it may not balance false positives and false negatives as well as the other models.\n",
    "\n",
    "4. **Training Time**:\n",
    "   - **KNN** is the fastest model to train with a time of **0.094 seconds**, making it highly efficient for training purposes.\n",
    "   - **Logistic Regression** also shows impressive efficiency with a training time of **1.023 seconds**.\n",
    "   - **LDA** takes slightly longer at **2.781 seconds**.\n",
    "   - **Decision Tree** takes the longest to train at **16.527 seconds**, which might be a consideration in time-sensitive applications.\n",
    "\n",
    "5. **Memory Utilization**:\n",
    "   - **Decision Tree** is the most memory-efficient model, with the lowest peak memory usage and memory increment.\n",
    "   - **KNN** and **Logistic Regression** have similar memory footprints, which are significantly higher than the Decision Tree but much lower than LDA.\n",
    "   - **LDA** requires the most memory, which could be a limiting factor in resource-constrained environments.\n",
    "\n",
    "### Overall Conclusion:\n",
    "\n",
    "- **Efficiency and Performance Balance**: If you're looking for a balance between efficiency (both in terms of memory and training time) and performance (in terms of Precision-Recall AUC, ROC AUC, and F1 Score), **Logistic Regression** appears to be the best choice among the models evaluated.\n",
    "  \n",
    "- **High Precision and Recall**: If the primary goal is to maximize precision and recall, and computational resources are less of a concern, **LDA** and **Logistic Regression** are strong contenders.\n",
    "\n",
    "- **Resource Constraints**: If memory usage and training time are critical constraints, **Decision Tree** offers a good balance, albeit with some trade-offs in terms of ROC AUC and F1 Score.\n",
    "\n",
    "- **Speed Priority**: For applications where training speed is the top priority, **KNN** stands out, though it does require a significant amount of memory and doesn't perform as well on ROC AUC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of feature engineering methods \n",
    "- For Manual Feature Engineering\n",
    "    - Feature Hashing was considered but due to the large number of records (fearing collisions a lot) it was not implemented.\n",
    "    - Feature binning was done to FICO scores\n",
    "    - Created a new feature Debt to income Ratio by loan_amount/annual_inc\n",
    "- Applied Principal Component analysis but the accuracy remained somewhat unchanged hence not used in further evaluating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying manual feature engineering and evaluating the models on the test dataset, we observe the following results:\n",
    "- Logistic Regression Accuracy: 0.9106651218995653\n",
    "- KNN Accuracy: 0.875758368526616\n",
    "- LDA Accuracy: 0.8983069850880143\n",
    "- Decision Tree Accuracy: 0.8029425321722664\n",
    "\n",
    "1. **Logistic Regression** has shown a notable improvement with an accuracy of **91.07%**. This improvement indicates that the manual feature engineering steps were particularly effective for this model, likely due to the creation of features that better represent the underlying patterns in a way that logistic regression can leverage.\n",
    "\n",
    "2. **KNN** has an accuracy of **87.58%**. While this is a respectable score, the improvement from manual feature engineering might not be as pronounced as with Logistic Regression. This could be due to KNN's reliance on distance metrics, which might not benefit as much from the engineered features without further tuning of the distance metric or feature weighting.\n",
    "\n",
    "3. **LDA** shows an accuracy of **89.83%**, indicating a positive impact from the feature engineering. LDA benefits from features that help to linearly separate the classes, and the engineered features seem to aid in this aspect.\n",
    "\n",
    "4. **Decision Tree** has the lowest accuracy among the models at **80.29%**. While Decision Trees are inherently good at feature selection and can build complex decision boundaries, the manual features might not provide significant additional information or could even introduce complexity that doesn't improve the model's performance.\n",
    "\n",
    "### Overall Conclusion:\n",
    "\n",
    "- **Most Effective Model**: After manual feature engineering, **Logistic Regression** stands out as the most effective model with the highest accuracy. This suggests that the transformations and new features introduced are particularly well-suited for a model that benefits from linear relationships.\n",
    "\n",
    "- **Moderate Improvements**: **LDA** also benefits from the feature engineering, showing a decent improvement. The engineered features likely help in defining a more separable linear space for LDA to operate in.\n",
    "\n",
    "- **Lesser Impact on KNN and Decision Tree**: **KNN** and **Decision Tree** show lesser improvements from manual feature engineering. KNN might require additional considerations such as feature scaling or distance metric tuning, and Decision Trees might already perform their form of feature engineering implicitly through splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametric Tuning \n",
    "- Based on the Conclusion we have chosen Logistic Regression and LDA to be further optimized \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Logistic Regression \n",
    "- **Parameter Grid**: Defined a grid of hyperparameters for Logistic Regression, focusing on the regularization strength (`C`) and the penalty type (`penalty`). A reduced range of `C` was used for faster processing and stronger regularization, and `l2` penalty was chosen for simplicity.\n",
    "- **GridSearchCV**: Utilized GridSearchCV to systematically work through the specified parameter grid, performing 5-fold cross-validation for each parameter combination, and identifying the combination that yielded the best accuracy.\n",
    "- **Parallel Processing**: Employed `n_jobs=-1` to use all available CPU cores, speeding up the grid search process.\n",
    "\n",
    "### Model Evaluation:\n",
    "- **Best Parameters and Score**: After fitting GridSearchCV with the transformed training data, the best hyperparameters (`C=0.01`, `penalty='l2'`) and the best cross-validation accuracy score (`0.8696`) were printed.\n",
    "- **Validation Performance**: The Logistic Regression model, with the best hyperparameters, was evaluated on the validation data, resulting in an accuracy of `0.9153`.\n",
    "- **Test Performance**: Finally, the model was assessed on a separate test dataset, yielding an accuracy of `0.9150`, closely matching the validation performance.\n",
    "\n",
    "### Conclusion for Logistic Regression:\n",
    "The hyperparameter tuning process demonstrated the effectiveness of the preprocessing steps combined with the optimized Logistic Regression model. The selection of `C=0.01` indicates a preference for stronger regularization, which likely helped prevent overfitting and contributed to the model's robust generalization performance.\n",
    "\n",
    "The model achieved high accuracy on both the validation and test datasets (`~0.915`), underscoring its predictive capability. The close agreement between validation and test accuracies suggests that the model is well-calibrated and not overfitting to the training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For LDA\n",
    "\n",
    "### Phase 1: LDA with 'svd' Solver (SVD stands for (Singular Value Decomposition))\n",
    "- **Solver**: You first conducted a grid search specifically for the 'svd' solver, which does not support shrinkage. This solver is often effective for datasets where the number of features is large or when multicollinearity is present in the features.\n",
    "- **GridSearchCV**: A single-parameter grid specifying `{'solver': ['svd']}` was used to fit the LDA model using the 'svd' solver.\n",
    "- **Fit**: The grid search was applied to the transformed training data (`X_train_transformed`), and the best parameters and scores were recorded.\n",
    "\n",
    "### Phase 2: LDA with 'lsqr' and 'eigen' Solvers with Shrinkage\n",
    "- **Solver**: The second grid search targeted the 'lsqr' and 'eigen' solvers, both of which support shrinkage. Shrinkage can help improve model performance, especially when dealing with small sample sizes or highly correlated features.\n",
    "- **Shrinkage**: A range of shrinkage values, including 'auto', was explored to determine the optimal level of regularization.\n",
    "- **GridSearchCV**: This grid search explored combinations of solvers and shrinkage values using the parameter grid defined in `param_grid_lda`.\n",
    "- **Error Handling**: The `error_score='raise'` parameter was set to raise errors immediately if any fit failed, providing immediate feedback on potential issues.\n",
    "\n",
    "### Model Selection and Evaluation\n",
    "- **Best Model Selection**: After performing both grid searches, the code compares the best scores from each to select the overall best LDA model.\n",
    "- **Evaluation**: The best LDA model, determined to be the one with the 'svd' solver, was then used to make predictions and evaluate performance on both validation and test datasets.\n",
    "\n",
    "### Results and Conclusion:\n",
    "- **Best Parameters**: The grid search identified the 'svd' solver as yielding the best cross-validation score (`0.8788`), indicating that, for your dataset, this solver without shrinkage was optimal.\n",
    "- **Validation Performance**: The LDA model with the 'svd' solver achieved an accuracy of `0.8983` on the validation set, showcasing strong predictive performance.\n",
    "- **Test Performance**: Similarly, the model maintained its high accuracy on the test set (`0.8981`), suggesting good generalizability.\n",
    "- **Classification Report**: The detailed classification report for the test set revealed excellent precision and recall across both classes, with an overall accuracy of `0.90`. This indicates that the LDA model is highly effective in distinguishing between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with the other  models\n",
    "\n",
    "The Logistic Regression model shows a significant improvement, achieving the highest accuracy on the test set among all models. This suggests that hyperparameter tuning and feature engineering had a substantial positive impact.\n",
    "The LDA model also shows strong performance, indicating that the chosen 'svd' solver was effective for this dataset.\n",
    "The KNN model's accuracy suggests an improvement, assuming the original model had lower performance.\n",
    "The Decision Tree model's performance is the lowest among the tuned models but might still represent an improvement or be competitive with its original performance.\n",
    "\n",
    "\n",
    "After tuning and applying manual feature engineering, the updated performance metrics for the models on the test set are as follows:\n",
    "\n",
    "- **Logistic Regression Accuracy:** 0.9150128938221773 (Best parameters: {'C': 0.01, 'penalty': 'l2'})\n",
    "- **LDA Accuracy on Test Data:** 0.8981325758991416\n",
    "\n",
    "\n",
    "The other two models\n",
    "- **Decision Tree Accuracy on Test Data:** 0.800712586114537\n",
    "- **KNN Accuracy on Test Data:** 0.8774401714193171\n",
    "\n",
    "\n",
    "Comparing these results to the initial accuracies before tuning and feature engineering:\n",
    "\n",
    "- **Logistic Regression:** Increased from 0.9106651218995653 to 0.9150128938221773\n",
    "- **KNN:** Slight increase from 0.875758368526616 to 0.8774401714193171\n",
    "- **LDA:** Decrease from initial 0.8983069850880143 (no change in accuracy after feature engineering)\n",
    "- **Decision Tree:** Decrease from initial 0.8029300743730613 to 0.800712586114537\n",
    "\n",
    "The Logistic Regression model saw a slight improvement after tuning and feature engineering, indicating that these steps were beneficial for this particular model. KNN also saw a minor increase in accuracy. However, the LDA model did not show a change in accuracy, suggesting that the manual feature engineering and tuning did not impact its performance. The Decision Tree model experienced a slight decrease in accuracy, which might indicate that the model became slightly overfitted after the feature engineering process or that the changes made were not beneficial for this model type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
